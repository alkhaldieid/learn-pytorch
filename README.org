#+TITLE: Learning the PyTorch Library
#+STARTUP: overview
#+ROAM_KEY: cite:Imambi2021



* Why PyTorch?
Because TF installation in any envirnoment other than Ubuntu sucks. 
* chapter 2
cite:Imambi2021
setting up source block for
** python session 
#+BEGIN_SRC python :results output :
  import os
  print( os.path)
#+END_SRC

#+RESULTS:
: <module 'posixpath' from '/home/alkhaldieid/anaconda3/envs/fastai/lib/python3.8/posixpath.py'>
** ipython session 
#+BEGIN_SRC python :results output
  import os
  print( os.path)
  from torchvision import models
#+END_SRC

#+RESULTS:
: <module 'posixpath' from '/home/alkhaldieid/anaconda3/envs/fastai/lib/python3.8/posixpath.py'>

#+BEGIN_SRC ipython :session :results output drawer
import os
print(os.path)
#+END_SRC

#+RESULTS:
:results:
<module 'posixpath' from '/home/alkhaldieid/anaconda3/envs/fastai/lib/python3.8/posixpath.py'>
:end:

#+BEGIN_SRC ipython :session :results output drawer
from torchvision import models
#+END_SRC

#+RESULTS:
:results:
:end:
* using kaggle example from here https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch
#+BEGIN_SRC ipython :session :results output drawer
  from __future__ import print_function, division
  
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.optim import lr_scheduler
  from torch.autograd import Variable
  import numpy as np
  import torchvision
  from torchvision import datasets, models, transforms
  import matplotlib.pyplot as plt
  import time
  import os
  import copy
  
  plt.ion()
  
  use_gpu = torch.cuda.is_available()
  if use_gpu:
      print("Using CUDA")
#+END_SRC

#+RESULTS:
:results:
Using CUDA
:end:

Loading this dataset with pytorch is really easy using ImageFolder as the labels are specified by the folders names.


#+BEGIN_SRC ipython :session :results output drawer
  data_dir = '/home/alkhaldieid/repos/datasets/iciar/dataset'
  TRAIN = 'train'
  VAL = 'validation'
  TEST = 'test'
  
  # VGG-16 Takes 224x224 images as input, so we resize all of them
  data_transforms = {
      TRAIN: transforms.Compose([
          # Data augmentation is a good practice for the train set
          # Here, we randomly crop the image to 224x224 and
          # randomly flip it horizontally. 
          transforms.RandomResizedCrop(224),
          transforms.RandomHorizontalFlip(),
          transforms.ToTensor(),
      ]),
      VAL: transforms.Compose([
          transforms.Resize(256),
          transforms.CenterCrop(224),
          transforms.ToTensor(),
      ]),
      TEST: transforms.Compose([
          transforms.Resize(256),
          transforms.CenterCrop(224),
          transforms.ToTensor(),
      ])
  }
  
  image_datasets = {
      x: datasets.ImageFolder(
          os.path.join(data_dir, x), 
          transform=data_transforms[x]
      )
      for x in [TRAIN, VAL, TEST]
  }
  
  dataloaders = {
      x: torch.utils.data.DataLoader(
          image_datasets[x], batch_size=8,
          shuffle=True, num_workers=4
      )
      for x in [TRAIN, VAL, TEST]
  }
  
  dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}
  
  for x in [TRAIN, VAL, TEST]:
      print("Loaded {} images under {}".format(dataset_sizes[x], x))
      
  print("Classes: ")
  class_names = image_datasets[TRAIN].classes
  print(image_datasets[TRAIN].classes)
#+END_SRC

#+RESULTS:
:results:
Loaded 376 images under train
Loaded 12 images under validation
Loaded 12 images under test
Classes: 
['Benign', 'InSitu', 'Invasive', 'Normal']
:end:
#+BEGIN_SRC ipython :session :results file drawer
def imshow(inp, title=None):
    inp = inp.numpy().transpose((1, 2, 0))
    # plt.figure(figsize=(10, 10))
    plt.axis('off')
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)

def show_databatch(inputs, classes):
    out = torchvision.utils.make_grid(inputs)
    imshow(out, title=[class_names[x] for x in classes])

# Get a batch of training data
inputs, classes = next(iter(dataloaders[TRAIN]))
show_databatch(inputs, classes)
#+END_SRC

#+RESULTS:
:results:
[[file:# Out[7]:
[[file:./obipy-resources/Hg5dsx.png]]]]
:end:

#+BEGIN_SRC ipython :session :results output drawer
def visualize_model(vgg, num_images=6):
    was_training = vgg.training
    
    # Set model for evaluation
    vgg.train(False)
    vgg.eval() 
    
    images_so_far = 0

    for i, data in enumerate(dataloaders[TEST]):
        inputs, labels = data
        size = inputs.size()[0]
        
        if use_gpu:
            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
        else:
            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)
        
        outputs = vgg(inputs)
        
        _, preds = torch.max(outputs.data, 1)
        predicted_labels = [preds[j] for j in range(inputs.size()[0])]
        
        print("Ground truth:")
        show_databatch(inputs.data.cpu(), labels.data.cpu())
        print("Prediction:")
        show_databatch(inputs.data.cpu(), predicted_labels)
        
        del inputs, labels, outputs, preds, predicted_labels
        torch.cuda.empty_cache()
        
        images_so_far += size
        if images_so_far >= num_images:
            break
        
    vgg.train(mode=was_training) # Revert model back to original training state
#+END_SRC

#+RESULTS:
:results:
:end:

This helper function will give us the accuracy of our model on the test set.


#+BEGIN_SRC ipython :session :results output drawer
def eval_model(vgg, criterion):
    since = time.time()
    avg_loss = 0
    avg_acc = 0
    loss_test = 0
    acc_test = 0
    
    test_batches = len(dataloaders[TEST])
    print("Evaluating model")
    print('-' * 10)
    
    for i, data in enumerate(dataloaders[TEST]):
        if i % 100 == 0:
            print("\rTest batch {}/{}".format(i, test_batches), end='', flush=True)

        vgg.train(False)
        vgg.eval()
        inputs, labels = data

        if use_gpu:
            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
        else:
            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)

        outputs = vgg(inputs)

        _, preds = torch.max(outputs.data, 1)
        loss = criterion(outputs, labels)

        loss_test += loss.data
        acc_test += torch.sum(preds == labels.data)

        del inputs, labels, outputs, preds
        torch.cuda.empty_cache()
        
    avg_loss = loss_test / dataset_sizes[TEST]
    avg_acc = acc_test / dataset_sizes[TEST]
    
    elapsed_time = time.time() - since
    print()
    print("Evaluation completed in {:.0f}m {:.0f}s".format(elapsed_time // 60, elapsed_time % 60))
    print("Avg loss (test): {:.4f}".format(avg_loss))
    print("Avg acc (test): {:.4f}".format(avg_acc))
    print('-' * 10)
#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC ipython :session :results output drawer
vgg16 = models.vgg16(pretrained=True)

#+END_SRC

#+RESULTS:
:results:
Downloading: "https://download.pytorch.org/models/vgg16-397923af.pth" to /home/alkhaldieid/.cache/torch/hub/checkpoints/vgg16-397923af.pth

:end:
#+BEGIN_SRC ipython :session :results output drawer
print(vgg16.classifier[6].out_features) # 1000 


# Freeze training for all layers
for param in vgg16.features.parameters():
    param.require_grad = False

# Newly created modules have require_grad=True by default
num_features = vgg16.classifier[6].in_features
features = list(vgg16.classifier.children())[:-1] # Remove last layer
features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs
vgg16.classifier = nn.Sequential(*features) # Replace the model classifier
print(vgg16)
#+END_SRC

#+RESULTS:
:results:
1000
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=4, bias=True)
  )
)
:end:
#+BEGIN_SRC ipython :session :results output drawer
resume_training = False
if use_gpu:
    vgg16.cuda() #.cuda() will move everything to the GPU side
    
criterion = nn.CrossEntropyLoss()

optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
print("Test before training")
eval_model(vgg16, criterion)
#+END_SRC

#+RESULTS:
:results:
Test before training
Evaluating model
----------
Test batch 0/2
Evaluation completed in 0m 0s
Avg loss (test): 0.2380
Avg acc (test): 0.2500
----------
<ipython-input-15-b90df545c40d>:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
:end:

#+BEGIN_SRC ipython :session :results output drawer
visualize_model(vgg16) #test before training

#+END_SRC

#+RESULTS:
:results:
Ground truth:
<ipython-input-8-dddcb065d591>:15: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
Prediction:
:end:

** training
#+BEGIN_SRC ipython :session :results output drawer
def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):
    since = time.time()
    best_model_wts = copy.deepcopy(vgg.state_dict())
    best_acc = 0.0
    
    avg_loss = 0
    avg_acc = 0
    avg_loss_val = 0
    avg_acc_val = 0
    
    train_batches = len(dataloaders[TRAIN])
    val_batches = len(dataloaders[VAL])
    
    for epoch in range(num_epochs):
        print("Epoch {}/{}".format(epoch, num_epochs))
        print('-' * 10)
        
        loss_train = 0
        loss_val = 0
        acc_train = 0
        acc_val = 0
        
        vgg.train(True)
        
        for i, data in enumerate(dataloaders[TRAIN]):
            if i % 100 == 0:
                print("\rTraining batch {}/{}".format(i, train_batches / 2), end='', flush=True)
                
            # Use half training dataset
            if i >= train_batches / 2:
                break
                
            inputs, labels = data
            
            if use_gpu:
                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())
            else:
                inputs, labels = Variable(inputs), Variable(labels)
            
            optimizer.zero_grad()
            
            outputs = vgg(inputs)
            
            _, preds = torch.max(outputs.data, 1)
            loss = criterion(outputs, labels)
            
            loss.backward()
            optimizer.step()
            
            loss_train += loss.data
            acc_train += torch.sum(preds == labels.data)
            
            del inputs, labels, outputs, preds
            torch.cuda.empty_cache()
        
        print()
        # * 2 as we only used half of the dataset
        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]
        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]
        
        vgg.train(False)
        vgg.eval()
            
        for i, data in enumerate(dataloaders[VAL]):
            if i % 100 == 0:
                print("\rValidation batch {}/{}".format(i, val_batches), end='', flush=True)
                
            inputs, labels = data
            
            if use_gpu:
                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
            else:
                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)
            
            optimizer.zero_grad()
            
            outputs = vgg(inputs)
            
            _, preds = torch.max(outputs.data, 1)
            loss = criterion(outputs, labels)
            
            loss_val += loss.data
            acc_val += torch.sum(preds == labels.data)
            
            del inputs, labels, outputs, preds
            torch.cuda.empty_cache()
        
        avg_loss_val = loss_val / dataset_sizes[VAL]
        avg_acc_val = acc_val / dataset_sizes[VAL]
        
        print()
        print("Epoch {} result: ".format(epoch))
        print("Avg loss (train): {:.4f}".format(avg_loss))
        print("Avg acc (train): {:.4f}".format(avg_acc))
        print("Avg loss (val): {:.4f}".format(avg_loss_val))
        print("Avg acc (val): {:.4f}".format(avg_acc_val))
        print('-' * 10)
        print()
        
        if avg_acc_val > best_acc:
            best_acc = avg_acc_val
            best_model_wts = copy.deepcopy(vgg.state_dict())
        
    elapsed_time = time.time() - since
    print()
    print("Training completed in {:.0f}m {:.0f}s".format(elapsed_time // 60, elapsed_time % 60))
    print("Best acc: {:.4f}".format(best_acc))
    
    vgg.load_state_dict(best_model_wts)
    return vgg
#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC ipython :session :results output drawer
vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)
torch.save(vgg16.state_dict(), 'vgg16v1iciar.pt')
#+END_SRC

#+RESULTS:
:results:
Epoch 0/2
----------
Training batch 0/23.5
Validation batch 0/2
Epoch 0 result: 
Avg loss (train): 0.1678
Avg acc (train): 0.3936
Avg loss (val): 0.2373
Avg acc (val): 0.2500
----------

Epoch 1/2
----------
<ipython-input-26-259c7331c612>:71: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
Training batch 0/23.5
Validation batch 0/2
Epoch 1 result: 
Avg loss (train): 0.1421
Avg acc (train): 0.5319
Avg loss (val): 0.2452
Avg acc (val): 0.2500
----------


Training completed in 0m 36s
Best acc: 0.2500
:end:

#+BEGIN_SRC ipython :session :results output drawer
eval_model(vgg16, criterion)

#+END_SRC

#+RESULTS:
:results:
Evaluating model
----------
Test batch 0/2
Evaluation completed in 0m 0s
Avg loss (test): 0.2162
Avg acc (test): 0.5000
----------
<ipython-input-15-b90df545c40d>:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)
:end:

#+BEGIN_SRC ipython :session :results output drawer

vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)
torch.save(vgg16.state_dict(), 'vgg16v1iciar.pt')
#+END_SRC
My personal notes and code for learning PyTorch
* investigating more models 
<<models>>
** include all pretrained models in one dict
make sure you are in the right conda envirnoment
#+BEGIN_SRC ipython :session :results output drawer
import os
print(os.path)
#+END_SRC

#+RESULTS:
:results:
<module 'posixpath' from '/home/alkhaldieid/anaconda3/envs/fastai/lib/python3.8/posixpath.py'>
:end:

#+BEGIN_SRC ipython :session :results nil 
  import torchvision.models as models
  pretrained_models = {
  "resnt18" : models.resnet18(pretrained=True),
  "alexnet" : models.alexnet(pretrained=True),
  "squeezenet" : models.squeezenet1_0(pretrained=True),
  "vgg16" : models.vgg16(pretrained=True),
  "densenet" : models.densenet161(pretrained=True),
  "inception" : models.inception_v3(pretrained=True),
  "googlenet" : models.googlenet(pretrained=True),
  "shufflenet" : models.shufflenet_v2_x1_0(pretrained=True),
  "mobilenet_v2" : models.mobilenet_v2(pretrained=True),
  "mobilenet_v3_large" : models.mobilenet_v3_large(pretrained=True),
  "mobilenet_v3_small" : models.mobilenet_v3_small(pretrained=True),
  "resnext50_32x4d" : models.resnext50_32x4d(pretrained=True),
  "wide_resnet50_2" : models.wide_resnet50_2(pretrained=True),
  "mnasnet" : models.mnasnet1_0(pretrained=True)
      }
  
#+END_SRC

#+RESULTS:
: # Out[1]:

fastai doesn't have monilnet_V3 large or small, therefore a seperate conda env that has the latest Pytorch has been created with the name torch.

Autocompletion is terrible with jedi. However, the goto def is nice. 

